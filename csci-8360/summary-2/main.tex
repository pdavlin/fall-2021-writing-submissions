% BEGIN TEMPLATE
\documentclass[11pt]{article}
\usepackage{graphicx}
\usepackage{hyperref} 
\usepackage{xcolor}
\usepackage{nameref}
\usepackage{listings}
\usepackage{float}
\usepackage[title]{appendix}
\usepackage[ruled]{algorithm2e}
\graphicspath{ {../../images/} }
\bibliographystyle{acm}
% CHANGE THESE
\newcommand{\courseListing}{CSCI 8360}
\newcommand{\courseName}{Machine Learning for Text}
\newcommand{\assignmentTitle}{Summary \#2}
\newcommand{\assignmentSubtitle}{Efficiency Optimizations for Search Query Processing}
\usepackage{geometry}
\geometry{margin=1in}

\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}
\urlstyle{same}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\lstdefinestyle{mystyle}{
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\begin{document}
  \input{../../templates/titlepage.tex}
  \graphicspath{{./images/}}
  In the process of information retrieval in unstructured data, a typical form of input is the query.
  Speaking generally, a query is an input of one or more keywords provided to the system, which interprets them in order to return the most relevant information.
  The content in the system is typically organized into an index that groups documents together, and then ranks them, based on the frequency of terms they contain.
  For any query, the system is able to return the ranked list of documents that corresponds to the keywords within.
  In situations where a query contains multiple terms, the system uses the intersection of these lists in order to return a complete listing of documents that are relevant.
  Preceding that, though, is the immediate issue of processing the query itself: removing extraneous terms, accounting for the position of terms, etc.
  There are several \textit{efficiency optimizations} outlined in the text (and in the corresponding course lectures) which make this process more straightforward.
  
  One such optimization is the \textit{skip pointer}, which allows for more efficient computation of the aforementioned intersections by enabling "shortcuts" over the list, skipping parts of it that are not necessary.
  This is particularly useful in cases where the lists differ in size; longer lists will have more elements, which means that fewer elements in the list will be relevant to the intersection.
  
  A second optimization is the \textit{champion list}.
  A champion list is a truncated inverted list with the top documents that have a high frequency ($p$) of a certain term, along with any other immediately relevant information.
  Using champion lists can make the process of resolving a query faster, time-wise, by using the champion lists for each term in the query to try and return a sufficient number ($q$) of result documents to the query.
  Of note is the fact that $p$ and $q$ can be adjusted depending on the application or needs, to increase the number of results as needed.
  An extension of this method is to create tiered champion lists that correspond to thresholds of term frequency in documents; items in tier 1 would have the highest number of hits to a certain number (say, a few documents that have a term appearing more than ten times), tier 2 would have the next list of items (say, with terms appearing more than five times and as many as ten), and so on.
  
  It is possible to optimize query processing with effective use of caching strategies.
  One such strategy is storing lists that have been used most recently in the cache, in a modified first-in, first-out order.
  Whenever a list is retrieved, it is timestamped and added to the cache.
  The cache itself is checked first, and if the list is there, its timestamp is updated.
  If the list is retrieved from disk, it is added to the cache; if the cache is full, the list or lists with the oldest timestamp is removed from the cache to make space, and the next query of the removed list consequently goes to the disk.
  The cumulative effect of this strategy is that the most frequently-accessed lists remain in the cache.
  Inversely, a system that with a high variety of queries may theoretically suffer from this approach--the expense of searching the cache first and replicating data there may be more expensive than directly searching on disk if the relative frequency of terms is approximately the same across the range of terms in the corpus.
  
  The last strategy is to utilize compression to reduce the size of the term dictionary, and reduce its size on disk or in memory.
  There are several ways to do this for the dictionary, such as forcing terms in the dictionary to be of a fixed width or using a dictionary of pointers that correspond to the starting point of terms in a sorted string of terms.
  The lists can be compressed, too--documents can be listed as IDs and delta encoding can be used.
  The first document in the list is stored, and every subsequent document is indexed by the difference between its ID number and the prior document's ID number.
  This allows for a smaller index to be used for searching.
  
  These optimizations are not an inclusive or exclusive list.
  They can be applied alone or in tandem, but the important takeaway from this section is that, as a designer of query processing systems, it is important to be conscious about the way that data is represented, stored, and accessed; subtle optimizations can drive substantial improvements to processing time and storage size when applied to a very large corpus.
  
\end{document}